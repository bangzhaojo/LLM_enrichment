{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3754cc7-92ba-494e-af1e-a9d5a5cb925a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "from transformers.generation.utils import GreedySearchDecoderOnlyOutput\n",
    "from transformers import GenerationConfig\n",
    "import textwrap\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cc81d0-4ce8-47c3-944f-003dfbcdd43c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m     response \u001b[38;5;241m=\u001b[39m decoded_output\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#### Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(textwrap\u001b[38;5;241m.\u001b[39mwrap(response))\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_alpaca\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     27\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m create_prompt(prompt)\n\u001b[0;32m     28\u001b[0m     response \u001b[38;5;241m=\u001b[39m generate_response(prompt, model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt: str, model) -> GreedySearchDecoderOnlyOutput:\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "    with torch.inference_mode():\n",
    "        return model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=128,\n",
    "        )\n",
    "\n",
    "    \n",
    "def format_response(response: GreedySearchDecoderOnlyOutput) -> str:\n",
    "    decoded_output = tokenizer.decode(response.sequences[0])\n",
    "    response = decoded_output.split(\"#### Response:\")[4].strip()\n",
    "    return \"\\n\".join(textwrap.wrap(response))\n",
    "\n",
    "\n",
    "def ask_alpaca(prompt: str, model=model) -> str:\n",
    "    prompt = create_prompt(prompt)\n",
    "    response = generate_response(prompt, model)\n",
    "    return (format_response(response))\n",
    "\n",
    "\n",
    "def create_prompt(instruction: str) -> str:\n",
    "    return PROMPT_TEMPLATE1.replace(\"[INPUT]\", instruction).replace(\"'\", '')\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath=None):\n",
    "    \n",
    "    if filepath == None:\n",
    "        return {}\n",
    "    \n",
    "    # Provide the path to your JSON file\n",
    "    text_file = filepath\n",
    "\n",
    "    # Load JSON data from the file\n",
    "    with open(text_file, \"r\") as json_file:\n",
    "        generated_formatted_venue_text = json.load(json_file)\n",
    "        \n",
    "    return generated_formatted_venue_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87310d6-edd6-4e4e-9b32-e9b62c47ba5c",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e2f02-3b9a-43ae-9ef3-7b1113143491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the target api dataset\n",
    "with open('../../data/category.json', 'r') as jsonfile:\n",
    "    prompt_venue_text = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639e6be-2c09-41bc-a5dd-0ffd1ecbd8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_venue_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635a223d-db2d-4ec7-926d-699ac9efd64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a6c05ffc4b48139ea82cd19f65c17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = r\"model/llama2-7B-hf\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309de3c-a19f-4402-aa22-0a61f29f8735",
   "metadata": {},
   "source": [
    "### few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b3f1c-072a-47fb-bb85-090885266e85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE1 = \"\"\"\n",
    "Your task is to determine the venue category based on its given information. You MUST choose ONE category ONLY from the provided list below.\n",
    "Airport, Animal Shelter, Antique Shop, Aquarium, Arcade, Art Gallery, Arts & Crafts Store, Athletic & Sport, Automotive Shop, Bagel Shop, Bakery, Bank, Bar, Beach, Beer Garden, Bike Shop, Bookstore, Bowling Alley, Brewery, Bridal Shop, Bridge, Building, Bus Station, Camera Store, Campground, Candy Store, Car Dealership, Car Wash, Casino, Cemetery, Church, Clothing Store, Coffee Shop, College & University, College Theater, Comedy Club, Concert Hall, Convenience Store, Convention Center, Cosmetics Shop, Cupcake Shop, Deli & Bodega, Department Store, Design Studio, Dessert Shop, Donut Shop, Drugstore & Pharmacy, Electronics Store, Event Space, Factory, Ferry, Flea Market, Flower Shop, Food Truck, Funeral Home, Furniture & Home Store, Garden, Gas Station & Garage, Gastropub, General Entertainment, Gift Shop, Government Building, Grocery Store, Gym & Fitness Center, Harbor & Marina, Hardware Store, Historic Site, Hobby Shop, Hotel, Housing Development, Ice Cream Shop, Jewelry Store, Laundry Service, Law School, Library, Light Rail, Mall, Medical Center, Medical School, Miscellaneous Shop, Mobile Phone Shop, Mosque, Movie Theater, Museum, Music Store, Music Venue, Nail Salon, Neighborhood, Nursery School, Office, Other Nightlife, Outdoors & Recreation, Paper & Office Supplies Store, Parking, Performing Arts Venue, Pet Store, Playground, Plaza, Pool, Pool Hall, Post Office, Professional & Other Places, Racetrack, Record Shop, Recycling Facility, Residential Building (Apartment & Condo), Rest Area, Restaurant, River, Road, Salon & Barbershop, Scenic Lookout, School, Sculpture Garden, Shop & Service, Smoke Shop, Snack Place, Spa & Massage, Spiritual Center, Sporting Goods Shop, Stadium, Storage Facility, Subway Station, Synagogue, Tanning Salon, Tattoo Parlor, Taxi, Tea Room, Theater, Thrift & Vintage Store, Toy & Game Store, Trade School, Train Station, Travel & Transport, Travel Lounge, Video Game Store, Video Store, Zoo\n",
    "### Example 1:\n",
    "\n",
    "#### Input:\n",
    "Venue name: T-Mobile\n",
    "Venue description: Visit T-Mobile New York cell phone stores and discover T-Mobile's best smartphones, cell phones, tablets, and internet devices. View our low cost plans with no annual service contracts.\n",
    "Venue review 1: Employees here try to tricky you into more expensive stuff. I've tried to get a plan for my wife that is the same I've got three hours ago in a different store and the lady said it doesn't exist. \n",
    "Venue review 2: LA, today we're spreading Unlimited Cheer with the T-Mobile Girl! Follow us on Twitter for your chance at a Life Without Limits prize pack. http://bit.ly/UFQPCH\n",
    "Venue review 3: Absolutely the worst customer service experience I have ever had. Can not believe how disorganized and rude these sales people. It's like they would rather not take your money. \n",
    "\n",
    "#### Response:\n",
    "Mobile Phone Shop.\n",
    "\n",
    "### Example 2:\n",
    "\n",
    "#### Input:\n",
    "Venue name: Eataly Flatiron\n",
    "Venue description: Eataly is a dynamic marketplace with restaurants that was created in Torino, Italy by Oscar Farinetti in 2007. There are 26 Eataly stores in the world.\n",
    "Venue review 1: Great meat section\n",
    "Venue review 2: Agnolotti tartuffo and poloeto meatballs. Also de Negroni was great\n",
    "Venue review 3: Tiramisu more like cream-my-pants-u. Incredibly delicious!\n",
    "\n",
    "#### Response:\n",
    "Grocery Store.\n",
    "\n",
    "### Example 3:\n",
    "\n",
    "#### Input:\n",
    "Venue name: Pitkin Education Center\n",
    "Venue description: None\n",
    "Venue review 1: Everyone has that face that screams: I want to punch you.\n",
    "Venue review 2: Agnolotti tartuffo and poloeto meatballs. Also de Negroni was great\n",
    "Venue review 3: The mayor is Tara...the one in the counseling center, in the back room, with the funk pens. Say ello to her.\n",
    "\n",
    "#### Response:\n",
    "College & University.\n",
    "\n",
    "### Your Task:\n",
    "#### Input:\n",
    "{\"[INPUT]\"}\n",
    "\n",
    "#### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2addd-b406-48a6-9f7b-6892eaec321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_formatted_venue_text = load_checkpoint('data/category_predict_name_des_tip_6500.json')\n",
    "count = 0   \n",
    "\n",
    "for index, (venue, info) in enumerate(prompt_venue_text.items()):\n",
    "    if venue not in generated_formatted_venue_text.keys():\n",
    "        \n",
    "        new_info = {}\n",
    "        new_info['text'] = info['prompt']\n",
    "        new_info['generated'] = ask_alpaca(info['prompt'])\n",
    "        new_info['truth'] = info['label']\n",
    "        \n",
    "        generated_formatted_venue_text[venue] = new_info\n",
    "    \n",
    "    if (index+1)%100 == 0:\n",
    "        print(f\"{(index+1)*100/len(prompt_venue_text):.2f} %\")\n",
    "        \n",
    "    if (index+1)%100 == 0:\n",
    "        # print(f\"{(index+1)*100/len(venue_text):.2f} %\")\n",
    "        \n",
    "        filename = f\"data/category_predict_name_des_tip_{index+1}.json\"\n",
    "        with open(filename, \"w\") as json_file:\n",
    "            json.dump(generated_formatted_venue_text, json_file)\n",
    "            \n",
    "    count = index\n",
    "\n",
    "filename = f\"data/category_predict_name_des_tip_6711.json\"\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(generated_formatted_venue_text, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52406567-2b65-4e74-bdba-4dadb912c9d7",
   "metadata": {},
   "source": [
    "### Second Round few-shot to Correct the Labels that don't Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9789877-8a20-47bc-91ef-65e6e641a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/category_predict_name_des_tip_6711.json', 'r') as jsonfile:\n",
    "    generated_formatted_venue_text = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f988be4-3ba0-4cf7-a8d0-d3549acd5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = []\n",
    "\n",
    "for index, (venue, info) in enumerate(generated_formatted_venue_text.items()):\n",
    "    category_list.append(info['truth'])\n",
    "\n",
    "categories = set(sorted(category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dc058be-2532-438d-83bb-f09697278d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE2 = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "You are provided a venue category not present in the given standard list. Match it to the closest category from the standard list. Choose ONLY ONE category as your response.\n",
    "Standard Venue Categories: Electronics Store, Light Rail, Music Store, Animal Shelter, Theater, Smoke Shop, Historic Site, Airport, Snack Place, Salon & Barbershop, Antique Shop, Jewelry Store, Bookstore, Playground, Toy & Game Store, Pool Hall, Furniture & Home Store, Mobile Phone Shop, Thrift & Vintage Store, College Theater, Bagel Shop, Synagogue, Housing Development, Dessert Shop, Museum, College & University, Tea Room, Tanning Salon, Food Truck, Restaurant, Library, Storage Facility, Plaza, Shop & Service, Miscellaneous Shop, Hobby Shop, Racetrack, Train Station, Pet Store, Laundry Service, Medical School, Scenic Lookout, Zoo, Sporting Goods Shop, Bakery, Deli & Bodega, Road, Harbor & Marina, Office, Bowling Alley, Gym & Fitness Center, Aquarium, Athletic & Sport, Candy Store, Sculpture Garden, Campground, Casino, Convenience Store, Church, Grocery Store, Government Building, Post Office, Gastropub, Bank, Paper & Office Supplies Store, Automotive Shop, Trade School, Other Nightlife, Video Game Store, Department Store, Travel Lounge, Donut Shop, General Entertainment, Rest Area, Stadium, Law School, Video Store, Convention Center, Arts & Crafts Store, Ice Cream Shop, Nursery School, Car Wash, Neighborhood, Brewery, Beach, Pool, Mosque, Ferry, Concert Hall, Coffee Shop, School, Residential Building (Apartment & Condo), Factory, Parking, Art Gallery, Record Shop, Professional & Other Places, Design Studio, Hotel, Arcade, Bike Shop, Spa & Massage, Cupcake Shop, Tattoo Parlor, Comedy Club, Nail Salon, Movie Theater, River, Camera Store, Taxi, Subway Station, Gift Shop, Flower Shop, Event Space, Bar, Building, Beer Garden, Bus Station, Gas Station & Garage, Spiritual Center, Music Venue, Clothing Store, Cosmetics Shop, Medical Center, Performing Arts Venue, Outdoors & Recreation, Funeral Home, Garden, Travel & Transport, Car Dealership, Bridge, Cemetery, Hardware Store, Mall, Bridal Shop, Drugstore & Pharmacy, Recycling Facility, Flea Market.\n",
    "\n",
    "#### Example 1:\n",
    "### Input: \n",
    "Venue Category: Park\n",
    "\n",
    "### Response:\n",
    "Outdoors & Recreation.\n",
    "\n",
    "#### Example 2:\n",
    "### Input: \n",
    "Venue Category: Computer Store\n",
    "\n",
    "### Response:\n",
    "Electronics Store.\n",
    "\n",
    "#### Your task:\n",
    "### Input:\n",
    "Venue Category: {\"[INPUT]\"}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "def create_prompt(instruction: str) -> str:\n",
    "    return PROMPT_TEMPLATE2.replace(\"[INPUT]\", instruction).replace(\"'\", '')\n",
    "\n",
    "def generate_response(prompt: str, model) -> GreedySearchDecoderOnlyOutput:\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=0.75,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "    with torch.inference_mode():\n",
    "        return model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=128,\n",
    "        )\n",
    "\n",
    "def format_response(response: GreedySearchDecoderOnlyOutput) -> str:\n",
    "    decoded_output = tokenizer.decode(response.sequences[0])\n",
    "    response = decoded_output.split(\"### Response:\")[3].strip()\n",
    "    return \"\\n\".join(textwrap.wrap(response))\n",
    "\n",
    "def ask_alpaca(prompt: str, model=model) -> str:\n",
    "    prompt = create_prompt(prompt)\n",
    "    response = generate_response(prompt, model)\n",
    "    return (format_response(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c85bba-3fd2-4fa4-960b-27a8630b439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 %\n",
      "2.98 %\n",
      "4.47 %\n",
      "5.96 %\n",
      "7.45 %\n",
      "8.94 %\n",
      "10.43 %\n",
      "11.92 %\n",
      "13.41 %\n",
      "14.90 %\n",
      "16.39 %\n",
      "17.88 %\n",
      "19.37 %\n",
      "20.86 %\n",
      "22.35 %\n",
      "23.84 %\n",
      "25.33 %\n",
      "26.82 %\n",
      "28.31 %\n",
      "29.80 %\n",
      "31.29 %\n",
      "32.78 %\n",
      "34.27 %\n",
      "35.76 %\n",
      "37.25 %\n",
      "38.74 %\n",
      "40.23 %\n",
      "41.72 %\n",
      "43.21 %\n",
      "44.70 %\n",
      "46.19 %\n",
      "47.68 %\n",
      "49.17 %\n",
      "50.66 %\n",
      "52.15 %\n",
      "53.64 %\n",
      "55.13 %\n",
      "56.62 %\n",
      "58.11 %\n",
      "59.60 %\n",
      "61.09 %\n",
      "62.58 %\n",
      "64.07 %\n",
      "65.56 %\n",
      "67.05 %\n",
      "68.54 %\n",
      "70.03 %\n",
      "71.52 %\n",
      "73.01 %\n",
      "74.50 %\n",
      "75.99 %\n",
      "77.48 %\n",
      "78.97 %\n",
      "80.46 %\n",
      "81.95 %\n",
      "83.45 %\n",
      "84.94 %\n",
      "86.43 %\n",
      "87.92 %\n",
      "89.41 %\n",
      "90.90 %\n",
      "92.39 %\n",
      "93.88 %\n",
      "95.37 %\n",
      "96.86 %\n",
      "98.35 %\n",
      "99.84 %\n"
     ]
    }
   ],
   "source": [
    "#corrected_prediction = load_checkpoint('data/category_predict_name_des_tip_corrected_5500.json')\n",
    "corrected_prediction = load_checkpoint()\n",
    "\n",
    "for index, (venue, info) in enumerate(generated_formatted_venue_text.items()):\n",
    "    \n",
    "    if venue not in corrected_prediction.keys():\n",
    "        if info['generated'] == '' or info['generated'][:4] == 'None':\n",
    "            corrected_prediction[venue] = info\n",
    "        else:\n",
    "            generated = info['generated'].split('<')[0].strip().strip('.')\n",
    "\n",
    "            if generated not in categories:\n",
    "                new_info = {}\n",
    "                new_info['text'] = info['text']\n",
    "                new_info['generated'] = ask_alpaca(generated)\n",
    "                new_info['truth'] = info['truth']\n",
    "                corrected_prediction[venue] = new_info\n",
    "\n",
    "            else:\n",
    "                corrected_prediction[venue] = info\n",
    "        \n",
    "    if (index+1)%100 == 0:\n",
    "        print(f\"{(index+1)*100/len(generated_formatted_venue_text):.2f} %\")\n",
    "        \n",
    "    if (index+1)%1000 == 0:\n",
    "        # print(f\"{(index+1)*100/len(venue_text):.2f} %\")\n",
    "        \n",
    "        filename = f\"../../result/category_predict_name_des_tip_corrected_{index+1}.json\"\n",
    "        with open(filename, \"w\") as json_file:\n",
    "            json.dump(corrected_prediction, json_file)\n",
    "            \n",
    "    count = index\n",
    "\n",
    "filename = f\"../../result/category_predict_name_des_tip_corrected_{count+1}.json\"\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(corrected_prediction, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819919c-e532-4807-906c-bea1e8553213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
